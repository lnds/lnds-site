---
title: "Reporte del Clima"
authors: [admin]
subtile: "9 desaf칤os en 9 lenguajes (2 de 9, primera parte)"
date: 2016-03-31T08:25:11-03:00
slug: "reporte-del-clima"
aliases: [/blog/lnds/2016/3/31/reporte-del-clima]
draft: false
tags: ['desaf칤os', 'lenguajes de programaci칩n', 'programaci칩n', 'go', 'rust','erlang','haskell','scala','kotlin', 'clojure','fsharp','swift']
image:
  placement: 3
---


[Jaco Pastorius](//es.wikipedia.org/wiki/Jaco_Pastorius) es uno de esos
m칰sicos que te deja una profunda impresi칩n cuando lo escuchas. En
particular, no volver치s a percibir el sonido del bajo de la misma forma
despu칠s de escucharlo.[Su estilo ha influenciado a grandes del rock y
el jazz, como el gran [Flea](//es.wikipedia.org/wiki/Flea)[
de Red Hot Chili Peppers, o [Geddy Lee](//es.wikipedia.org/wiki/Geddy_Lee)
 de Rush, quien coloca a Jaco en la cima m치s alta.

> *"Sometimes a little bit of his fairy dust might rub off on you when
> you pretend to play like he
> does."

![](//d2dspjyoh5c79p.cloudfront.net/2438e961-f6d3-11e5-a13c-3371c0364c63-aa9f18b7)

쯈u칠 tiene que ver esto con estos raros lenguajes nuevos?

En realidad nada. O muy poco, pero a mi me gusta Jaco Pastorius y su
m칰sica fue la principal banda sonora mientras resolv칤a el segundo
desaf칤o de esta tarea, que me he auto impuse de visitar nueve lenguajes
de programaci칩n en nueve ejercicios.

Este segundo desaf칤o, se llama Weather Report (reporte del tiempo), para
homenajear a la famosa banda de jazz fusi칩n, en donde toc칩 Jaco al
inicio de su carrera.

## Es un mundo concurrente

Creo que una de las caracter칤sticas m치s importantes de un lenguaje
moderno tiene que ver con la manera en que aborda la programaci칩n
paralela.

La programaci칩n paralela es una forma de programaci칩n concurrente, en
que aprovechamos las capacidades de los sistema multiprocesador.

Voy a recurrir a las definiciones 맋adas por Ricardo Galli en su libro
["Principios y Algoritmos de Concurrencia"](/blog/lnds/2015/11/15/principios-y-algoritmos-de-concurrencia):

> **Programaci칩n Concurrente:** es la composici칩n de m칩dulos que se
> ejecutan independientemente, de forma as칤ncrona y no determinista.\
> **Programaci칩n Paralela:** el paralelismo es una forma de ejecutar
> programas concurrentes. La programaci칩n concurrente es una forma de
> estructurar los programas, no el n칰mero de procesadores que usa para
> su ejecuci칩n.

> "Los problemas de procesos concurrentes no son exclusividad del
> procesamiento paralelo, tambi칠n ocurren con un 칰nico procesador. Los
> estudios de concurrencia y paralelismo son diferentes. El primero se
> ocupa de la correcta composici칩n de componentes no deterministas, el
> segundo de la eficiencia asint칩tica de programas de comportamiento
> determinista."

Como les dije antes, vamos a resolver un problema de programaci칩n
paralela. Los aspectos m치s caracter칤sticos de 맗rogramaci칩n concurrente
los estudiaremos m치s adelante en otros desaf칤os.

## Consultando el reporte del tiempo

El desaf칤o 2 consiste en construir una aplicaci칩n que obtenga el clima
de distintas ciudades, usando la API de
[OpenWeatherMap.org](//openweathermap.org/).

Se debe crear un programa que reciba a trav칠s de la l칤nea de comandos
una lista de ciudades. Este programa debe realizar una consulta al 맋el
sitio OpenWeatherMap.org para obtener el informe del tiempo para cada
una de las ciudades. El resultado se debe ordenar de forma descendente,
desde la mayor a la menor temperatura. El resultado debe contener, la
ciudad, la temperatura m치xima y las condiciones del clima. Adem치s el
programa debe informar 만l tiempo cronol칩gico ocupado para descargar la
informaci칩n. Si se pasa el par치metro -p el programa hace la consulta
"en paralelo" para cada ciudad.

Por ejemplo, este es el resultado de la ejecuci칩n del programa al
momento de escribir estas lineas:

     $ weather Berlin Santiago Boston Madrid Concepcion Mexico
     Mexico 26.00 nubes rotas
     Santiago 15.00 cielo claro
     Concepcion 15.00 nubes rotas
     Madrid 10.70 nubes dispersas
     Boston 10.00 cielo claro
     Berlin 03.00 cielo claro
     tiempo ocupado para generar el reporte: 00:00:02.105

Si lo ejecuto con el par치metro -p:

     $ weather -p Berlin Santiago Boston Madrid Concepcion Mexico
     Mexico 26.00 nubes rotas
     Santiago 15.00 cielo claro
     Concepcion 15.00 nubes rotas
     Madrid 10.80 nubes dispersas
     Boston 10.00 cielo claro
     Berlin 03.00 cielo claro
     tiempo ocupado para generar el reporte: 00:00:01.546

Notar치n que en este caso la versi칩n paralela del programa toma un tiempo
menor (1,546 segundos versus 2.105 segundos).

La siguiente tabla muestra los tiempos de ejecuci칩n de la versi칩n Go del
programa, ejecut치ndolo de manera secuencial y paralela (con el par치metro
-p). Los tiempos est치n en segundos, partiendo con 1 ciudad hasta llegar
a 10 ciudades. Fueron probados en un Macbook Pro con un procesador Intel
I7 de 4 cores.

    Ciudades sec         par     s
    1        1,180     1,633     0,72
    2        0,829     0,807     1,03
    3        1,246     1,043     1,19
    4        1,670     0,716     2,33
    5        1,974     1,276     1,55
    6        2,388     1,725     1,38
    7        2,546     1,303     1,95
    8        2,761     1,470     1,88
    9        3,244     1,803     1,80
    10       3,754     1,207     3,11

La columna s muestra el speedup, o factor de mejora, que mide cuanto
mejora el tiempo de ejecuci칩n en paralelo con respecto a la ejecuci칩n
secuencial.

Estos valores no deben considerarse una medici칩n precisa, es necesario
hacer muchas m치s para determinar un valor adecuado de speedup. Pero nos
da una idea del efecto de paralelizar la consulta.

Si tenemos 4 cores, y asumimos que el 90% del proceso se puede ejecutar
en paralelo, tenemos un l칤mite te칩rico de 3,07 de speedup, de acuerdo a
la [Ley de Amdahl](//es.wikipedia.org/wiki/Ley_de_Amdahl).

Con los valores de la tabla de arriba calcul칠 el Speedup Te칩rico de
acuerdo a las leyes de Amdahl y de
[Gustafson](//es.wikipedia.org/wiki/Ley_de_Gustafson), que incluyo s칩lo
como dato anecd칩tico, en este caso consider칠 el valor p = 0,90 para el
c치lculo de este par치metro:

    # Gustafson Amhdal
     (p = 0,9) (p=0,9)
    1  0,7503 0,7432
    2  1,0245 1,0244
    3  1,1752 1,1718
    4  2,1992 2,0581
    5  1,4923 1,4667
    6  1,3459 1,3331
    7  1,8586 1,7837
    8  1,7904 1,7265
    9  1,7193 1,6660
    10 2,8992 2,5682

Si no entienden de que se trata todo esto les sugiero leer mis posts
sobre la Ley de Amdahl
([ac치](/blog/2009/09/el-problema-de-paralelizar.html),
[ac치](/blog/2009/09/el-problema-de-paralelizar-2.html) y
[ac치](/blog/2009/09/el-problema-de-paralelizar-3.html)), o
mejor a칰n, el cap칤tulo respectivo en [mi
libro](//amzn.to/17bKPdO)멇릦

El par치metro p de la ley de Amdahl es la proporci칩n del programa que se
ejecuta en paralelo. Para entender por qu칠 consider칠 un valor de p =
0,90 les voy a describir la forma general de mi soluci칩n a este desaf칤o.

# Consultas en paralelo

Si resolvemos el problema para consultar el clima de una lista de
ciudades en forma secuencial, una soluci칩n posible se puede expresar con
el siguiente algoritmo (escrito en seudo c칩digo):

     Sea N la cantidad de ciudades.

     Sea Cities[0..N-1] un arreglo con los nombres de las ciudades.

     Sea Reporte[0..N-1] un arreglo con los reportes del tiempo para cada ciudad.

     Sea ArgV[] un arreglo con los argumentos del programa recibidos en la linea de comandos.
     
     for i = 0; i < N; i++ {
        Cities[i] = ArgV[i]
     }
     for i = 0; i < N; i++ {
       Reports[i] = CallApiOpenWeatherMap(Cities[i])
     }

     SortInPlaceByTemp(Reports)
     
     for i = 0; i < N; i++{
        PrintReport(Reports[i])
     }

Gr치ficamente este programa se ejecuta de la siguiente manera:

{{<figure caption="ejecuci칩n secuencial del programa" src="//d2dspjyoh5c79p.cloudfront.net/6623c943-f74a-11e5-a13c-3371c0364c63-aa9f18b7">}}

Cada c칤rculo representa una sub rutina, en este caso, el circulo de
color celeste representa las llamadas a la API de OpenWeatherMap. El
resultado de esta llamada lo guardamos en un elemento de nuestro arreglo
de reportes, que representamos con cajas grises. Despu칠s ordenamos ese
arreglo de reportes, esto est치 representado por el c칤rculo de color
naranja con la palabra sort.

Podemos mejorar el tiempo si ejecutamos las llamadas a la API de forma
paralela, de este modo:

![](//d2dspjyoh5c79p.cloudfront.net/ddc628d4-f74a-11e5-a13c-3371c0364c63-aa9f18b7)

En teor칤a, tendremos una fracci칩n del tiempo usada en la operaci칩n en
paralelo y una fracci칩n secuencial que corresponde al ordenamiento de
los datos (sort). 쮺u치l es la proporci칩n del tiempo ocupada en las
llamadas en paralelo? Ese es el par치metro p, yo le asign칠 un valor de
0,9, porque asumo que el 90% del tiempo se gasta en consultar la API y
ordenar ocupa el otro 10%. Esto es un valor arbitrario, determinarlo en
forma precisa escapa a los objetivos de este ejercicio, pero ustedes
pueden intentar determinarlo con mayor precisi칩n.

쮺칩mo reflejamos esta paralelizaci칩n en nuestro algoritmo?

Del siguiente modo:

    Sea N la cantidad de ciudades.
     Sea Cities[0..N-1] un arreglo con los nombres de las ciudades.
     Sea Reporte[0..N-1] un arreglo con los reportes del tiempo para cada ciudad.
     Sea ArgV[] un arreglo con los argumentos del programa recibidos en la linea de comandos.
     for i = 0; i < N; i++ {
        Cities[i] = ArgV[i]
     }
     par for i = 0; i < N; i++ {
       Reports[i] = CallApiOpenWeatherMap(Cities[i])
     }
     SortInPlaceByTemp(Reports)
     for i = 0; i < N; i++{
        PrintReport(Reports[i])
     }

El truco fue cambiar el for central por un **par for.**

{{<figure caption="yaaaa?!!" src="//d2dspjyoh5c79p.cloudfront.net/93cea765-f74b-11e5-a13c-3371c0364c63-aa9f18b7">}}

Ya s칠 que esto lo encuentran sospechoso, no se preocupen, se los voy a
explicar.

Hay algunos lenguajes que tienen construcciones similares a lo que he
llamado **par for.**

Este par for es una estructura de control que ejecuta en paralelo las
instrucciones del cuerpo del ciclo. Hay compiladores de Fortran y C para
super computadores que tienen construcciones similares a esta.

En un supercomputador con muchos procesadores lo que hace una estructura
de control como esta es ejecutar el cuerpo del ciclo en un procesador
distintos. Esta estructura de control se encarga de sincronizar el
t칠rmino de cada una de las ejecuciones secuenciales.

Pero esto est치 disponible en uno de los lenguajes que estamos revisando.
La soluci칩n en Swift del desaf칤o 2 (que pueden ver
[ac치](//github.com/lnds/9d9l/tree/master/desafio2/swift)) usa algo muy
similar al seudo c칩digo.

```swift
    var reports = [ApiResult?]()
    for i in 1...cities.count {
       reports.append(nil)
    }
    let globalQueue = dispatch_get_global_queue(QOS_CLASS_USER_INITIATED, 0)
    dispatch_apply(cities.count, globalQueue) {
       i in 
      let index = Int(i)+2 // cities start from 2
      let city = cities[index]
     let rep = callApi(city, apiKey:apiKey)
       reports[Int(i)] = rep
    }
    // sort...
```

En Swift usamos [Grand Central Dispatch](//en.wikipedia.org/wiki/Grand_Central_Dispatch), que es un
modelo de concurrencia desarrollado por
Apple.

Lo que hacemos es crear una cola de tareas global (globalQueue). Sobre
esta cola despacharemos tareas (tasks).

La funci칩n dispatch\_apply() es similar a la estructura de control par
for, ejecutar치 una clausura (el c칩digo entre { }) en forma concurrente.
Esta funci칩n se encarga de esperar que terminen todas las tareas.

La ventaja de este problema es que es muy f치cil de paralelizar. S칩lo
debemos tener cuidado de esperar que las descargas de informaci칩n
finalicen antes de ordenar e imprimir el resultado. Es por esto que
podemos en nuestro for acceder al arreglo reports tranquilamente.

Pero las cosas no son tan sencillas si usamos otros lenguajes
tradicionales tendr칤amos que hacer algo del estilo (en seudo c칩digo):

    for city 말n cities {
       task { city =>
      맜al report = callApi(city)
      맓ock(reports)
      reports[city] = report
        unlock(reports)
       }
    }
    wait_for_tasks()
    sortInPlace(reports)

Ac치 task es una suerte de thread o tarea que se ejecuta en forma
concurrente. Notar que tenemos que asegurar acceso exclusivo al arreglo
reports para actualizarlo y tenemos que invocar alg칰n tipo de primitiva
que nos asegure que las tareas han finalizado (wait\_for\_tasks()).

## Las ventajas de la programaci칩n funcional concurrente

Pero veamos el problema con los ojos de la programaci칩n funcional. Este
problema tiene una forma cl치sica, conocida como map-reduce.

Funcionalmente lo que tenemos que hacer es mapear cada ciudad con su
reporte y luego ordenar (reducir).

En seudo c칩digo funcional, este problema se puede escribir as칤:

    print $ sort $ (map apiCall cities)

Esto es en realidad un seudo Haskell, que dice que debemos imprimir el
resultado de ordenar el mapping de ciudades a sus reportes (el reporte
se obtiene con la funci칩n apiCall).

Y para paralelizar esto simplemente hacemos:

    print $ sort $ (pmap apiCall cities)

La funci칩n pmap es un map pero ejecutado en paralelo.

{{<figure caption="Yaaaa 쯆tra vez????" src="//d2dspjyoh5c79p.cloudfront.net/b11f21f7-f750-11e5-a13c-3371c0364c63-aa9f18b7">}}

S칤, parece magia, pero las soluciones en
[Clojure](//github.com/lnds/9d9l/tree/master/desafio2/clojure) y
[Scala](//github.com/lnds/9d9l/tree/master/desafio2/scala) de este
problema son as칤 de sencillas:

Scala:

```scala
    def parFetch(cities:List[String]) : Unit = {
      val reports = (cities.par map (city => apiCall(city))).toList
      printReports(reports)
    }
```

Clojure

```clojure
    ((print-weather (sort-reports (pmap weather-api r))))
```

Esta soluci칩n aparte de concisa nos permite abstraernos de las
sincronizaci칩n y todas las complicaciones de la programaci칩n
concurrente. La inmutabilidad permite ver este problema como un flujo de
informaci칩n que va pasando de funci칩n a funci칩n. La abstracci칩n pmap es
el equivalente al par for en el mundo funcional.

Pero hay otra forma de resolver este problema y es con canales,
siguiendo el estilo
[CSP](//en.wikipedia.org/wiki/Communicating_sequential_processes)Communicating
Sequential Process (propuesto originalmente por Hoare en 1978).

Ac치 lo que hacemos es lo siguiente:


    ch := new_channel(type: Report)
    for _ := 0 to N-1 {
     맊ity := cities[i]
     맚ask { chan_put (ch, apiCall(city)) }
    }
    for _ := 0 to N-1 {
      report.append(chan_get(ch))
    }
    sort_in_place(report)
    print(report)

Piensen en el channel como una cola de mensajes. En este caso task { }
ejecuta una tarea de forma concurrente. Dentro de esta tarea colocamos
en el canal ch el resultado de invocar la API de OpenWeatherMap, usando
la primitiva chan\_put(). Esta es una operaci칩n que se ejecuta de forma
sincronizada.

Posteriormente vaciamos esta cola de mensajes (el canal) usando la
primitiva chan\_get(), colocando cada mensaje (que corresponde al
reporte del clima) en una lista report.

Hay que notar que el orden en que sacamos los reportes del canal no
tiene por que coincidir con el orden en que ejecutamos las tareas. Es
decir, si el arreglo de ciudades contiene los valores {Boston, Santiago,
Madrid, Londres}, en el segundo loop podr칤amos obtener los reportes de
{Santiago, Londres, Boston, Madrid} o cualquier otro orden.

Esta es la forma en que resolvemos este problema en
[Go](//github.com/lnds/9d9l/blob/master/desafio2/go/weather.go) y
[Rust](//github.com/lnds/9d9l/tree/master/desafio2/rust).

Go:

```go
    ch := make(chan WeatherReport)
    for _, city := range cities {
        go fetch(city, ch) // fetch call api and put response in ch
    }
    for range cities {
        rep := <- ch
        reports = append(reports, rep)
    }
```

Rust:

```rust
    let (tx, rx) = mpsc::channel();
    for city in cities {
        let tx = tx.clone();
        let city = city.clone();
        thread::spawn(move || {
          let report = api_call(&city, &api_key);
          tx.send(report).unwrap();
        });
    }
    let mut reports : Vec<ApiResult> = Vec::with_capacity(cities.len());
    for _ in cities {
      let rep = rx.recv().unwrap();
      reports.push(rep);
    }
```

La soluci칩n en Rust tiene m치s "ruido" que la versi칩n en Go debido a
las reglas de "borrowing" de este lenguaje, algo que veremos en
detalle en un art칤culo espec칤fico sobre este lenguaje.

## Cinco soluciones

En este art칤culo les he mostrado 5 soluciones de este problema:

Swift: en
[https://github.com/lnds/9d9l/blob/master/desafio2/swift](//github.com/lnds/9d9l/blob/master/desafio2/swift)

Scala:
en[https://github.com/lnds/9d9l/blob/master/desafio2/scala](//github.com/lnds/9d9l/blob/master/desafio2/scala)

Clojure:
en[https://github.com/lnds/9d9l/blob/master/desafio2/clojure](//github.com/lnds/9d9l/blob/master/desafio2/clojure)

Go:
en[https://github.com/lnds/9d9l/blob/master/desafio2/go](//github.com/lnds/9d9l/blob/master/desafio2/go)

Rust:
en[https://github.com/lnds/9d9l/blob/master/desafio2/rust](//github.com/lnds/9d9l/blob/master/desafio2/rust)\

En la segunda parte de este art칤culo completaremos los otros lenguajes.

Espero sus comentarios y aportes.

Y para que amenicen este post les dejo Birdland de Weather Report, donde
pueden apreciar a Jaco Pastorius ejecutando dos tareas en paralelo ;)

{{<youtube pqashW66D7o>}}
